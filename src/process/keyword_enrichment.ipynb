{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# We find the US country code\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "#sparkql query to get the country name and their respective quids from wikidata\n",
    "query = \"\"\"#List of present-day countries and capital(s)\n",
    "SELECT DISTINCT ?country ?countryLabel\n",
    "WHERE\n",
    "{\n",
    "  ?country wdt:P31 wd:Q3624078 .\n",
    "\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" }\n",
    "}\n",
    "ORDER BY ?countryLabel\"\"\"\n",
    "\n",
    "'''\n",
    "query internet dataset:\n",
    "endpoint_url (string): url of corresponding dataset\n",
    "query (string): sparksql query\n",
    "'''\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    # TODO adjust user agent; see https://w.wiki/CX6\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "results = get_results(endpoint_url, query)\n",
    "\n",
    "#Build a country numpy array {quid, country name}\n",
    "country_array = []\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    country_id = result[\"country\"]['value'].split('/')[-1]\n",
    "    #country_dict[country_id] = result[\"countryLabel\"]['value']\n",
    "    country_array.append([country_id, result[\"countryLabel\"]['value']])\n",
    "country_array = np.array(country_array)\n",
    "\n",
    "US_index = np.argwhere(country_array=='United States of America')[0][0]\n",
    "US_code = country_array[US_index][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# We extract the US speakers\n",
    "speaker_df = pd.read_parquet(\"speaker_attributes.parquet\")\n",
    "\n",
    "nationality_list = list(speaker_df['nationality'])\n",
    "names_list = [item[0] for item in speaker_df.values]\n",
    "my_df = pd.DataFrame({\"nationality_list\": nationality_list, \"names_list\": names_list})\n",
    "\n",
    "indexes = [index for index in range(len(nationality_list)) if (nationality_list[index] is not None) and (names_list[index] is not None) and US_code in nationality_list[index]]\n",
    "\n",
    "speaker_flat_list = [names_list[i][j] for i in indexes for j in range(len(names_list[i])) if len(names_list[i][j])>=4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Dictionary: \n"
     ]
    }
   ],
   "source": [
    "# We extract speakers that appeared in nytime 2019\n",
    "path_to_file = 'quotes-2019-nytimes.json.bz2'\n",
    "path_to_out = 'quotes-2019-us.json.bz2'\n",
    "\n",
    "Dict = {}\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance)  # loading a sample\n",
    "            quote = instance['quotation']\n",
    "            speaker = instance['speaker']\n",
    "\n",
    "            if any(word in quote for word in speaker_flat_list):\n",
    "                common_american_speaker = [word in quote for word in speaker_flat_list]\n",
    "\n",
    "                if speaker_flat_list[common_american_speaker.index(True)] in Dict:\n",
    "                    Dict[speaker_flat_list[common_american_speaker.index(True)]] = Dict[speaker_flat_list[common_american_speaker.index(True)]] + 1\n",
    "                else:\n",
    "                    Dict[speaker_flat_list[common_american_speaker.index(True)]] = 1\n",
    "            else:\n",
    "                pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the enriched keywords\n",
    "a_file = open(\"Dict_quotes-2019-nytimes.pkl\", \"wb\")\n",
    "pickle.dump(Dict, a_file)\n",
    "a_file.close()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}